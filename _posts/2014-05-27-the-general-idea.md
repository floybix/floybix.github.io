---
layout: post
tagline: "Supporting tagline"
tags : [comportex]
---
{% include JB/setup %}


Greetings!

Like many people, it seems, my passion for artificial intelligence has
been re-kindled recently. Douglas Hofstadter and Jeff Hawkins were the
main re-kindlers for me. Now I've set off exploring.

I'm hoping to push the boundaries of artificial intelligence, creating
something that can learn, explore, generalise, theorise, and surprise.

**Why?**

Because it would be so cool. Also, it seems self-evident that the
tools we build should have some basic intelligence. Software and
games use tricks to appear intelligent, but they are mindless
zombies, unable to
deal with even slightly new situations, and will happily bang their
heads against a brick wall until, um, they're taken out by a zombie
hunter, or something. Computational intelligence has the potential to
make technology do what we want, with **robust adaptability**. The
cost is giving up precisely defined behaviour, as well as vastly more
computation and memory requirements. Not to
mention the difficulty of developing all this. But smart people are
working on it. And it is fun.

**How?**

I'm convinced that Jeff Hawkins' [Hierarchical Temporal
Memory](https://numenta.com/technology/) (HTM) is the proper basis for
such computational intelligence. Of course, HTM is a general theory
and has not yet been worked out at a level of detail applicable to
most interesting problems. My strategy will be to focus on examples.
To attack specific problems as a way to inspire development of the
theory. I'll design simulations with opportunities for learning and
watch what goes wrong.

**But...**

HTM is based on a memory system, arranged in a hierarchy of increasing
abstraction, where the memory is simultaneously a predictive function.
So it can recognise things, or situations or whatever, and infer what
is happening and what may happen next. There is no emotion, no
desire, no fear. Just recognition, generalisation, analogy. This is
not scary. Zombies are scary. Intelligence, in and of itself, is not.
Of course every technology will be put to nasty uses, but I think it's
hard to argue that more intelligence is a bad thing.

Right, well, looks like we've got a lot of work to do. Better get on
with it.

*--Felix*
